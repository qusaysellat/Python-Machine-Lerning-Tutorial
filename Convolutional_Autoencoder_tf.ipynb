{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convolutional_Autoencoder_tf.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qusaysellat/Python-Machine-Lerning-Tutorial/blob/master/Convolutional_Autoencoder_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gne65oOb-ABY",
        "colab_type": "text"
      },
      "source": [
        "**THIS IS A CONVOLUTIONAL AUTO-ENCODER FOR** *MNIST DATASET*\n",
        "\n",
        ">NAME : [QUSAY SELLAT](https://github.com/qusaysellat)\n",
        "\n",
        ">FOR MORE INFORMATION ABOUT 'MNIST' VISIT\n",
        "[THIS SITE](http://yann.lecun.com/exdb/mnist/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rppuZi7G4eE9",
        "colab_type": "code",
        "outputId": "e18824e9-7115-4f9b-c72f-122281dd4835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "# first lets import used libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9HI031_4sng",
        "colab_type": "code",
        "outputId": "09850f53-cc6a-4b13-ebe6-ebb14d895b3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "# then import MNIST dataset\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('/tmp/data/', one_hot = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-28338b28f8c6>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teGALhfd5mFu",
        "colab_type": "code",
        "outputId": "0dff3345-f7e9-4468-be32-287eff073bdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# lets try to play with this data set\n",
        "\n",
        "# lets see the dimensions of train, validation, and test datasets - note that mnist is a named tupple\n",
        "print(mnist.train._images.shape)\n",
        "print(mnist.train._labels.shape)\n",
        "print(mnist[1]._images.shape)\n",
        "print(mnist[1]._labels.shape)\n",
        "print(getattr(mnist, 'test')._images.shape)\n",
        "print(getattr(mnist, 'test')._labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(55000, 784)\n",
            "(55000, 10)\n",
            "(5000, 784)\n",
            "(5000, 10)\n",
            "(10000, 784)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3o_fuNL6DHu",
        "colab_type": "code",
        "outputId": "f8b3daf4-57dd-4030-f952-0490551b6ba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# lets take a sample of our data and discover its values\n",
        "print('the first 8 labels in the training set:')\n",
        "print(mnist[0]._labels[:8, : ])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the first 8 labels in the training set:\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-XDHgRr6JcT",
        "colab_type": "code",
        "outputId": "6500d64f-202d-46ac-a7ea-79ab39fe144c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "# now lets draw the sample we have just viewed\n",
        "\n",
        "canvas = np.zeros((28, 28 * 8))\n",
        "for i in range(8):\n",
        "  canvas[:, 28 * i : 28 * (i + 1)] = mnist[0].images[i, :].reshape([28 ,28])\n",
        "  \n",
        "plt.figure(figsize = (8, 64))\n",
        "plt.imshow(canvas, origin = 'upper', cmap ='gray')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAABaCAYAAABg8oUyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n51wG/A3YOeecy8D/AYR8Ik9rN28qAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x4608 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hdnx23gI6nBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now we have to initialize important hyperparameters\n",
        "LR = 0.001\n",
        "steps = 7001\n",
        "batch_size = 128 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkOBt4YaN28J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lets define parameters for network structure\n",
        "I = 784\n",
        "O = 10\n",
        "dropout = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQrGZ1n8OBt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lets define the function that encapsulates the forward propagation operations of our model\n",
        "def forward_phase(x_dict, n_classes, dropout, reuse, is_training) :\n",
        "  \n",
        "  # first we have to ensure sharing the variables between training and testing phases\n",
        "  with tf.variable_scope('CNN', reuse = reuse) :\n",
        "    \n",
        "    # extract the images from the input\n",
        "    x = x_dict['images']\n",
        "    \n",
        "    # reshape images so that they can be passed to tf layers\n",
        "    x = tf.reshape(x, [-1, 28, 28, 1])\n",
        "    \n",
        "    # lets start with encoder phase\n",
        "\n",
        "    # first conv layer\n",
        "    x = tf.layers.conv2d(x, 32, 5, padding='SAME', activation = tf.nn.relu)\n",
        "    \n",
        "    # first pooling layer\n",
        "    x = tf.layers.max_pooling2d(x, 2, 2)\n",
        "    \n",
        "    # second conv layer\n",
        "    x = tf.layers.conv2d(x, 64, 3, padding='SAME', activation = tf.nn.relu)\n",
        "    \n",
        "    # second pooling layer\n",
        "    x = tf.layers.max_pooling2d(x, 2, 2)\n",
        "    \n",
        "    # flatten x to fit the dense layers\n",
        "    x = tf.contrib.layers.flatten(x)\n",
        "    \n",
        "    # dense layer\n",
        "    x = tf.layers.dense(x, 512)\n",
        "    \n",
        "    # perform dropout if training phase\n",
        "    # x = tf.layers.dropout(x, rate = dropout, training = is_training)\n",
        "    \n",
        "    # this is the encoding\n",
        "    x = tf.layers.dense(x, 64)\n",
        "\n",
        "    # it's time to start with decoder phase\n",
        "\n",
        "    # reverse of dense layer\n",
        "    x = tf.layers.dense(x, 512)\n",
        "\n",
        "    # reverse of flattened layer\n",
        "    x = tf.layers.dense(x, 7*7*64)\n",
        "\n",
        "    # unflatten x to fit the deconvolutional layers\n",
        "    x = tf.reshape(x, shape=[-1, 7, 7, 64])\n",
        "\n",
        "    # reverse of pooling layer\n",
        "    x = tf.image.resize_bilinear(x, size=[14, 14], align_corners=None)\n",
        "\n",
        "    # reverse of convolutional layer\n",
        "    x = tf.contrib.layers.conv2d_transpose(x, kernel_size=3, padding='SAME', num_outputs=32, activation_fn=tf.nn.relu)\n",
        "\n",
        "    # reverse of pooling layer\n",
        "    x = tf.image.resize_bilinear(x, size=[28, 28], align_corners=None)\n",
        "\n",
        "    # reverse of convolutional layer\n",
        "    x = tf.contrib.layers.conv2d_transpose(x, kernel_size=5, padding='SAME', num_outputs=1, activation_fn=tf.nn.relu)\n",
        "\n",
        "    # reshape images so that they return to input shape\n",
        "    x = tf.reshape(x, [-1, 28*28])\n",
        "  \n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7FjYD0SQx1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lets define our model that will be fed into the estimator\n",
        "def model_fn(features, labels, mode) :\n",
        "  \n",
        "  # extract the logits\n",
        "  output_train = forward_phase(features, O, dropout, reuse = False, is_training = True)\n",
        "  output_test = forward_phase(features, O, dropout, reuse = True, is_training = False)\n",
        "  \n",
        "  # find predicted classes and prediction probabilities according to softmax\n",
        "  # pred_classes = tf.arg_max(logits_test, 1)\n",
        "  # pred_probs = tf.nn.softmax(logits_test)\n",
        "  \n",
        "  # if mode is PREDICT return the predicted classes\n",
        "  if mode == tf.estimator.ModeKeys.PREDICT :\n",
        "    return tf.estimator.EstimatorSpec(mode, output_test)\n",
        "  \n",
        "  # define loss function\n",
        "  # loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = tf.cast(labels, dtype = tf.int32), logits = logits_train))\n",
        "  loss_op = tf.reduce_mean(tf.square(tf.subtract(features['images'], output_train)))\n",
        "\n",
        "  # define optimizer function\n",
        "  train_op = tf.train.AdamOptimizer(LR).minimize(loss_op, global_step = tf.train.get_global_step())\n",
        "  \n",
        "  # define accuracy function\n",
        "  # accuracy_op = tf.metrics.accuracy(labels, pred_classes)\n",
        "  \n",
        "  if mode == tf.estimator.ModeKeys.EVAL :\n",
        "    preds = output_test\n",
        "  else :\n",
        "    preds = output_train\n",
        "    \n",
        "  # return calculated functions\n",
        "  return tf.estimator.EstimatorSpec(\n",
        "      mode = mode, \n",
        "      predictions = preds,\n",
        "      loss = loss_op,\n",
        "      train_op = train_op,\n",
        "      # eval_metric_ops = {'Accuracy' : accuracy_op}\n",
        "  )\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9mYeO3LubLV",
        "colab_type": "code",
        "outputId": "fd36fcd6-4664-4392-aa2f-4830ae24fcee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "# build the model\n",
        "model = tf.estimator.Estimator(model_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpems6uwrb\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpems6uwrb', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fde96863400>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIaUkIrHuCL_",
        "colab_type": "code",
        "outputId": "7ef26726-4d6e-4e59-df00-2206c580f829",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model\n",
        "\n",
        "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x = {'images' : mnist.train.images}, \n",
        "    y = mnist.train.labels, \n",
        "    batch_size = batch_size, \n",
        "    num_epochs = None, \n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "model.train(input_fn = input_fn, steps = steps)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From <ipython-input-8-e3349e6d8b2d>:15: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-8-e3349e6d8b2d>:18: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.MaxPooling2D instead.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From <ipython-input-8-e3349e6d8b2d>:30: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py:882: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpems6uwrb/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.111508615, step = 1\n",
            "INFO:tensorflow:global_step/sec: 2.9371\n",
            "INFO:tensorflow:loss = 0.014821371, step = 101 (34.049 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.93922\n",
            "INFO:tensorflow:loss = 0.008209398, step = 201 (34.022 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.94187\n",
            "INFO:tensorflow:loss = 0.0069444715, step = 301 (33.997 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.94843\n",
            "INFO:tensorflow:loss = 0.0063285925, step = 401 (33.912 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.96097\n",
            "INFO:tensorflow:loss = 0.0057038707, step = 501 (33.776 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.95217\n",
            "INFO:tensorflow:loss = 0.0052609895, step = 601 (33.870 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.95015\n",
            "INFO:tensorflow:loss = 0.0042979494, step = 701 (33.897 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.97028\n",
            "INFO:tensorflow:loss = 0.004418922, step = 801 (33.669 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.95432\n",
            "INFO:tensorflow:loss = 0.004089749, step = 901 (33.847 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.97517\n",
            "INFO:tensorflow:loss = 0.004625388, step = 1001 (33.615 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.96764\n",
            "INFO:tensorflow:loss = 0.004777154, step = 1101 (33.693 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.96881\n",
            "INFO:tensorflow:loss = 0.0041866065, step = 1201 (33.684 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.96876\n",
            "INFO:tensorflow:loss = 0.0038143846, step = 1301 (33.683 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.97824\n",
            "INFO:tensorflow:loss = 0.0035170969, step = 1401 (33.579 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.97292\n",
            "INFO:tensorflow:loss = 0.003578609, step = 1501 (33.636 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.98703\n",
            "INFO:tensorflow:loss = 0.0033660345, step = 1601 (33.481 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.95716\n",
            "INFO:tensorflow:loss = 0.0035983645, step = 1701 (33.813 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1776 into /tmp/tmpems6uwrb/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 2.95968\n",
            "INFO:tensorflow:loss = 0.0031427324, step = 1801 (33.788 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.98772\n",
            "INFO:tensorflow:loss = 0.0034950227, step = 1901 (33.476 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.97655\n",
            "INFO:tensorflow:loss = 0.0032018155, step = 2001 (33.590 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.97982\n",
            "INFO:tensorflow:loss = 0.003131184, step = 2101 (33.559 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.99362\n",
            "INFO:tensorflow:loss = 0.003191584, step = 2201 (33.405 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.98166\n",
            "INFO:tensorflow:loss = 0.0035130114, step = 2301 (33.538 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.97483\n",
            "INFO:tensorflow:loss = 0.0033189098, step = 2401 (33.615 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.89242\n",
            "INFO:tensorflow:loss = 0.0033615518, step = 2501 (34.574 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.92037\n",
            "INFO:tensorflow:loss = 0.0028974186, step = 2601 (34.242 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.9857\n",
            "INFO:tensorflow:loss = 0.0030326375, step = 2701 (33.492 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.01683\n",
            "INFO:tensorflow:loss = 0.0029218406, step = 2801 (33.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.99926\n",
            "INFO:tensorflow:loss = 0.0028550439, step = 2901 (33.347 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.0212\n",
            "INFO:tensorflow:loss = 0.002924244, step = 3001 (33.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.99603\n",
            "INFO:tensorflow:loss = 0.002692495, step = 3101 (33.379 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.00875\n",
            "INFO:tensorflow:loss = 0.0029789996, step = 3201 (33.238 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.00753\n",
            "INFO:tensorflow:loss = 0.0028883885, step = 3301 (33.249 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.99779\n",
            "INFO:tensorflow:loss = 0.0026463734, step = 3401 (33.357 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.004\n",
            "INFO:tensorflow:loss = 0.0028917028, step = 3501 (33.287 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 3567 into /tmp/tmpems6uwrb/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 2.98886\n",
            "INFO:tensorflow:loss = 0.0028523293, step = 3601 (33.458 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.01013\n",
            "INFO:tensorflow:loss = 0.0025104282, step = 3701 (33.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.02357\n",
            "INFO:tensorflow:loss = 0.0025629152, step = 3801 (33.073 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.99167\n",
            "INFO:tensorflow:loss = 0.0026471901, step = 3901 (33.433 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.98812\n",
            "INFO:tensorflow:loss = 0.0027106293, step = 4001 (33.460 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.98762\n",
            "INFO:tensorflow:loss = 0.002672226, step = 4101 (33.475 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.98877\n",
            "INFO:tensorflow:loss = 0.002516672, step = 4201 (33.454 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.97498\n",
            "INFO:tensorflow:loss = 0.0024362297, step = 4301 (33.614 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.97036\n",
            "INFO:tensorflow:loss = 0.002485175, step = 4401 (33.669 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.93479\n",
            "INFO:tensorflow:loss = 0.0027356853, step = 4501 (34.071 sec)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QG0NkjCucTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lets now test our trained model\n",
        "\n",
        "# it would be better if we visualize the results\n",
        "\n",
        "# number of examples per each row/column\n",
        "n = 8\n",
        "\n",
        "# we would like not to waste the space, lets define canvases for drawing\n",
        "canvas1 = np.zeros((28*n, 28*n))\n",
        "canvas2 = np.zeros((28*n, 28*n))\n",
        "\n",
        "for i in range(n) :\n",
        "  \n",
        "  # get the next batch\n",
        "  batch_x, batch_y = mnist.test.next_batch(n)\n",
        "  \n",
        "  # calculate the predicted values\n",
        "  input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "      x = {'images' : batch_x},\n",
        "      shuffle = False\n",
        "      )\n",
        "  decoded_x = list(model.predict(input_fn))\n",
        "  \n",
        "  for j in range(n) :\n",
        "     \n",
        "      # draw the images of true labels\n",
        "      canvas1[28 * i : 28 * (i + 1), 28 * j : 28 * (j + 1)] = batch_x[j].reshape([28, 28])\n",
        "      \n",
        "      # draw the images of predicted labels\n",
        "      canvas2[28 * i : 28 * (i + 1), 28 * j : 28 * (j + 1)] = decoded_x[j].reshape([28, 28])\n",
        "\n",
        "print('Original Digits:')      \n",
        "plt.figure(figsize = (n, n))\n",
        "plt.imshow(canvas1, origin = 'upper', cmap = 'gray')\n",
        "plt.show()\n",
        "  \n",
        "print('Reconstructed Digits:')\n",
        "plt.figure(figsize = (n, n))\n",
        "plt.imshow(canvas2, origin = 'upper', cmap = 'gray')\n",
        "plt.show()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}